{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize,rescale\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll use a dirty document dataset to get clean denoised document texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to manually build our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data():\n",
    "    \n",
    "    x_train = []\n",
    "    \n",
    "    for file in listdir('kdd/train'):\n",
    "    \n",
    "        img = imread('kdd/train/' + file)\n",
    "        \n",
    "        img = resize(img,(260,540),True)\n",
    "        \n",
    "        img = img.reshape(1,img.shape[0],img.shape[1])\n",
    "    \n",
    "        \n",
    "        x_train.append(img)\n",
    "        \n",
    "    \n",
    "    x_train = tuple(x_train)\n",
    "    \n",
    "    x_train = np.concatenate(x_train)\n",
    "    \n",
    "    y_train = [] \n",
    "    \n",
    "    \n",
    "    for file in listdir('kdd/train_cleaned'):\n",
    "    \n",
    "        img = imread('kdd/train_cleaned/' + file)\n",
    "        \n",
    "        img = resize(img,(260,540),True)\n",
    "        \n",
    "        y_train.append(img.reshape(1,img.shape[0],img.shape[1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_train = tuple(y_train)\n",
    "    \n",
    "    y_train = np.concatenate(y_train)\n",
    "    \n",
    "    x_test = []\n",
    "    \n",
    "    for file in listdir('kdd/test'):\n",
    "    \n",
    "        img = imread('kdd/test/' + file)\n",
    "        \n",
    "        img = resize(img,(260,540),True)\n",
    "        \n",
    "        x_test.append(img.reshape(1,img.shape[0],img.shape[1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_test = tuple(x_test)\n",
    "    \n",
    "    x_test = np.concatenate(x_test)\n",
    "    \n",
    "    return x_train,y_train,x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/.local/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/igor/.local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test = build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), 260, 540, 1))\n",
    "y_train = np.reshape(y_train, (len(x_train), 260, 540, 1))  \n",
    "x_test = np.reshape(x_test, (len(x_test), 260, 540, 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to split the dataset to train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = x_train[121:145]\n",
    "x_train = x_train[0:120]\n",
    "\n",
    "y_validation = y_train[121:145]\n",
    "y_train = y_train[0:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "input_shape = (260,540,1)\n",
    "batch_size=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=input_shape)\n",
    "downConv = Conv2D(32,(3,3),activation='relu',padding='same')(input_img)\n",
    "downConv = MaxPooling2D((2,2),padding='same')(downConv)\n",
    "downConv = Conv2D(32,(3,3),activation='relu',padding='same')(downConv)\n",
    "\n",
    "encoded = MaxPooling2D((2,2),padding='same')(downConv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "upConv = Conv2D(32,(3,3),activation='relu',padding='same')(encoded)\n",
    "upConv = UpSampling2D((2,2))(upConv)\n",
    "upConv = Conv2D(32,(3,3),activation='relu',padding='same')(upConv)\n",
    "upConv = UpSampling2D((2,2))(upConv)\n",
    "\n",
    "\n",
    "decoded = Conv2D(1,(3,3), activation='sigmoid', padding='same')(upConv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 260, 540, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 260, 540, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 130, 270, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 130, 270, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 65, 135, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 65, 135, 32)       9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 130, 270, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 130, 270, 32)      9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 260, 540, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 260, 540, 1)       289       \n",
      "=================================================================\n",
      "Total params: 28,353\n",
      "Trainable params: 28,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_img,decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_validation, y_validation),\n",
    "                verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
